version: '3.8'

services:
  # Ollama service
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    
  # The Intersect API
  intersect-api:
    build: .
    container_name: intersect-api
    ports:
      - "8000:8000"
    environment:
      - INTERSECT_API_KEY=${INTERSECT_API_KEY:-your-super-secret-api-key}
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=llama3.1
      - RATE_LIMIT_REQUESTS=10
      - RATE_LIMIT_WINDOW=60
    depends_on:
      - ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Nginx reverse proxy (optional)
  nginx:
    image: nginx:alpine
    container_name: intersect-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl  # Add your SSL certificates here
    depends_on:
      - intersect-api
    restart: unless-stopped

volumes:
  ollama_data:
